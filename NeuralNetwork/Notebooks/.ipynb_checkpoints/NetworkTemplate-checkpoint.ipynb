{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Template for ReverseLearning with Input Backprop\n",
    "# By Abraham Oliver, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import python3's print as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import data and prepare for use\n",
    "\n",
    "ARGUMENTS:\n",
    "    size - int - number of data in set\n",
    "\n",
    "RETURN:\n",
    "    ([input1, input2, input3, ...], [output_label1, output_label2, output_label3, ...])\n",
    "    where input(n) is in form [value1, value2, value3, ...]\n",
    "    and output_label(n) is in form [output_node1, output_node2, output_node3, ...]\n",
    "    \n",
    "NOTES:\n",
    "    - DO NOT CHANGE NAME\n",
    "    - Random import can be removed if not used\n",
    "\"\"\"\n",
    "from random import randint, random\n",
    "def newSet(size):\n",
    "    \"\"\"EXAMPLE\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    for s in range(size):\n",
    "        newInputs = [random() * randint(-10, 10) for i in range(3)]\n",
    "        data.append(newInputs)\n",
    "        labels.append([sum(newInputs)])\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start an interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PARAMETERS (DESIGN AT WILL)\n",
    "\n",
    "# Number of neurons in each layer where LAYERS[0] is the input and LAYERS[-1] is the output\n",
    "LAYERS = [3, 1]\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "LEARN_RATE = .01\n",
    "EPOCHS = 4000\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "# To change LOSS, go to cell 6\n",
    "# To change OPTIMIZER, go to cell 6\n",
    "\n",
    "# INPUT BACKPROP\n",
    "IB_EPOCHS = 400\n",
    "IB_LEARN_RATE = .01\n",
    "TARGET = [10.0]\n",
    "\n",
    "# To change LOSS for input backprop, go to cell 12\n",
    "# To change OPTIMIZER for input backprop, go to cell 12\n",
    "\n",
    "# Optional Input for prediction checking\n",
    "EXAMPLE = [[100.0, 200.0, 300.0]]\n",
    "\n",
    "# SETTINGS\n",
    "DEBUG = False\n",
    "DEBUG_INTERVAL = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Model Parameters (CUSTOMIZATION NOT NEEDED)\n",
    "\n",
    "# Input\n",
    "x = tf.placeholder(tf.float32, [None, LAYERS[0]], name=\"x\")\n",
    "# Weights\n",
    "w = [tf.Variable(tf.zeros([LAYERS[n], LAYERS[n + 1]]), name=\"w{0}\".format(n)) for n in range(len(LAYERS) - 1)]\n",
    "# Biases\n",
    "b = [tf.Variable(tf.ones([LAYERS[n + 1]]), name=\"b{0}\".format(n)) for n in range(len(LAYERS) - 1)]\n",
    "# Output\n",
    "def calc(inp, n = 0):\n",
    "    if n == len(LAYERS) - 2:\n",
    "        return tf.matmul(inp, w[n]) + b[n]\n",
    "    return calc(tf.matmul(inp, w[n]) + b[n], n + 1)\n",
    "y = calc(x)\n",
    "# Label\n",
    "y_ = tf.placeholder(tf.float32, [None, LAYERS[-1]], name=\"y_\")\n",
    "\n",
    "# Loss function\n",
    "loss = tf.reduce_mean(tf.pow(y_ - y, 2))\n",
    "# Training step\n",
    "train_step = tf.train.ProximalGradientDescentOptimizer(LEARN_RATE).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING *  *  *  *  *  *  *  *  *  * \n",
      "TRAINING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Train model (CUSTOMIZATION NOT NEEDED)\n",
    "\n",
    "# Initialize variables\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Status bar\n",
    "STATUS_INTERVAL = EPOCHS / 10\n",
    "\n",
    "# Train normal model\n",
    "print(\"TRAINING\", end=\"\")\n",
    "for i in range(EPOCHS):\n",
    "    # Get data\n",
    "    batch_inps, batch_outs = newSet(BATCH_SIZE)\n",
    "    \n",
    "    # Debug printing\n",
    "    if i % DEBUG_INTERVAL == 0 and DEBUG:\n",
    "        print(\"Weights ::\")\n",
    "        for i in w:\n",
    "            print(i.eval())\n",
    "        print(\"Biases ::\")\n",
    "        for i in b:\n",
    "            print(i.eval())\n",
    "        print(\"Loss :: {0}\\n\\n\".format(loss.eval(feed_dict={x: batch_inps, y_: batch_outs})))\n",
    "        \n",
    "    # Run train step\n",
    "    sess.run(train_step, feed_dict={x: batch_inps, y_: batch_outs})\n",
    "    \n",
    "    # Print status bar\n",
    "    if i % STATUS_INTERVAL == 0 and not DEBUG: print(\" * \", end=\"\")\n",
    "print(\"\\nTRAINING COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-af27029e4058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mEXAMPLE\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EXAMPLE :: {0} => {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXAMPLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXAMPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-af27029e4058>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(INPUT)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mEDIT\u001b[0m \u001b[0mLINE\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0mTO\u001b[0m \u001b[0mCUSTOMIZE\u001b[0m \u001b[0mPREDICTOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mEXAMPLE\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-bd62c9c89f62>\u001b[0m in \u001b[0;36mcalc\u001b[0;34m(inp, n)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLAYERS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1396\u001b[0m                                    \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                                    \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m                                    name=name)\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[0msparse_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_mat_mul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   1346\u001b[0m   \"\"\"\n\u001b[1;32m   1347\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[0;32m-> 1348\u001b[0;31m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1349\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    747\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    748\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    750\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2380\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1781\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1782\u001b[0m                          % op.type)\n\u001b[0;32m-> 1783\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, debug_python_shape_fn)\u001b[0m\n\u001b[1;32m    594\u001b[0m                                                              status)\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;31m# Convert TensorShapeProto values in output_shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 2 but is rank 1"
     ]
    }
   ],
   "source": [
    "# Use trained network\n",
    "def predict(INPUT):\n",
    "    \"\"\"\n",
    "    Get network prediction\n",
    "    \n",
    "    ARGUMENTS\n",
    "        INPUT - input vector. FORM: [[x0, x1, x2, ..., x(n-1)]] for n inputs\n",
    "        full - bool - Return full vector output if true and only argmax if false\n",
    "        \n",
    "    EDIT LINE 2 TO CUSTOMIZE PREDICTOR\n",
    "    \"\"\"\n",
    "    return calc(INPUT).eval()\n",
    "\n",
    "if EXAMPLE != []:\n",
    "    print(\"EXAMPLE :: {0} => {1}\".format(EXAMPLE, predict(EXAMPLE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save variables\n",
    "saved_weights = [i.eval() for i in w]\n",
    "saved_biases = [i.eval() for i in b]\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start new session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "optimal = tf.Variable(tf.zeros([1, LAYERS[0]]))\n",
    "# Input Weights\n",
    "w = [tf.constant(i) for i in saved_weights]\n",
    "# Input Biases\n",
    "b = [tf.constant(i) for i in saved_biases]\n",
    "# Output\n",
    "out = calc(optimal)\n",
    "# Label\n",
    "lbl = tf.constant(TARGET)\n",
    "\n",
    "# Training with quadratic cost and gradient descent with learning rate .01\n",
    "loss = tf.pow(tf.reduce_mean(lbl - out), 2)\n",
    "train_step = tf.train.ProximalGradientDescentOptimizer(LEARN_RATE).minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Train to find three inputs\n",
    "for i in range(IB_EPOCHS):\n",
    "    sess.run(train_step)\n",
    "\n",
    "print(\"OPTIMAL INPUT       :: {0}\".format(optimal.eval()))\n",
    "print(\"CALCULATED OUT      :: {0}\".format(calc(optimal.eval()).eval()))\n",
    "print(\"TARGET OUT          :: {0}\".format(TARGET))\n",
    "print(\"TARGET vs CALC LOSS :: {0}\".format(loss.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
